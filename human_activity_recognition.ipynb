{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Project: Human Activity Recognition (HAR) \n",
    "\n",
    "<br>\n",
    "Huamn Activity Recognition (HAR) has emerged as a key research area because of its use for many different applications and its connection to many different fields such as medicine and human-computer interactions. For this project, we will be learning and recognizing the physical activities of humans based on wearable sensors, namely accelerometers. There is a wide range of applications for this such as elderly monitoring, assisting the sick and disabled, weight-loss programs, and more. \n",
    "\n",
    "This project will use a HAR dataset from the website: http://groupware.les.inf.puc-rio.br/har\n",
    "\n",
    "In their experiment, 165,633 data samples were gathered from 4 subjects wearing accelerometers on their waist, left thigh, right arm, and right ankle. Each of the 4 sensors will give an x-y-z direction based on their position and orientation. Features such as age and body mass index were also considered. \n",
    "\n",
    "<img src=\"http://puu.sh/yHRJ4/80c40876bd.jpg\" height=\"200\" width=\"200\">\n",
    "\n",
    "The data will be used to verify 5 activity classes: if the subject is sitting, sitting down, standing, standing up, or walking. They did not specify what was the difference between sitting/sitting down or standing/standing up. \n",
    "\n",
    "Ugulino, who worked on the project, trained a classifier using the AdaBoost method and along with the C4.5 decision tree algorithm. His classifier accuracy was 99.4%. His research paper can be found on: http://groupware.les.inf.puc-rio.br/public/papers/2012.Ugulino.WearableComputing.HAR.Classifier.RIBBON.pdf. In his paper, he also provided a chart that includes other HAR researches using different datasets, their algorithms used, and their accuracy. No sample code was provided, so we will not use anything from past projects. \n",
    "\n",
    "For our project, we will test three different algorithms: Logistic Regression with and without cross validation, Support Vector Machines, and Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Visualize the Data\n",
    "\n",
    "First, we import the packages that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import linear_model, preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `pd.read_csv` to load the 'HAR_data.txt' file. It can be downloaded from the website mentioned before. <br>\n",
    "It has been renamed and changed to a txt file. Note that the data is separated by semicolons.<br>\n",
    "\n",
    "The first six lines of the pandas dataframe is printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>how_tall_in_meters</th>\n",
       "      <th>weight</th>\n",
       "      <th>body_mass_index</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>z3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y4</th>\n",
       "      <th>z4</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>debora</td>\n",
       "      <td>Woman</td>\n",
       "      <td>46</td>\n",
       "      <td>1.62</td>\n",
       "      <td>75</td>\n",
       "      <td>28.6</td>\n",
       "      <td>-3</td>\n",
       "      <td>92</td>\n",
       "      <td>-63</td>\n",
       "      <td>-23</td>\n",
       "      <td>18</td>\n",
       "      <td>-19</td>\n",
       "      <td>5</td>\n",
       "      <td>104</td>\n",
       "      <td>-92</td>\n",
       "      <td>-150</td>\n",
       "      <td>-103</td>\n",
       "      <td>-147</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>debora</td>\n",
       "      <td>Woman</td>\n",
       "      <td>46</td>\n",
       "      <td>1.62</td>\n",
       "      <td>75</td>\n",
       "      <td>28.6</td>\n",
       "      <td>-3</td>\n",
       "      <td>94</td>\n",
       "      <td>-64</td>\n",
       "      <td>-21</td>\n",
       "      <td>18</td>\n",
       "      <td>-18</td>\n",
       "      <td>-14</td>\n",
       "      <td>104</td>\n",
       "      <td>-90</td>\n",
       "      <td>-149</td>\n",
       "      <td>-104</td>\n",
       "      <td>-145</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>debora</td>\n",
       "      <td>Woman</td>\n",
       "      <td>46</td>\n",
       "      <td>1.62</td>\n",
       "      <td>75</td>\n",
       "      <td>28.6</td>\n",
       "      <td>-1</td>\n",
       "      <td>97</td>\n",
       "      <td>-61</td>\n",
       "      <td>-12</td>\n",
       "      <td>20</td>\n",
       "      <td>-15</td>\n",
       "      <td>-13</td>\n",
       "      <td>104</td>\n",
       "      <td>-90</td>\n",
       "      <td>-151</td>\n",
       "      <td>-104</td>\n",
       "      <td>-144</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>debora</td>\n",
       "      <td>Woman</td>\n",
       "      <td>46</td>\n",
       "      <td>1.62</td>\n",
       "      <td>75</td>\n",
       "      <td>28.6</td>\n",
       "      <td>-2</td>\n",
       "      <td>96</td>\n",
       "      <td>-57</td>\n",
       "      <td>-15</td>\n",
       "      <td>21</td>\n",
       "      <td>-16</td>\n",
       "      <td>-13</td>\n",
       "      <td>104</td>\n",
       "      <td>-89</td>\n",
       "      <td>-153</td>\n",
       "      <td>-103</td>\n",
       "      <td>-142</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>debora</td>\n",
       "      <td>Woman</td>\n",
       "      <td>46</td>\n",
       "      <td>1.62</td>\n",
       "      <td>75</td>\n",
       "      <td>28.6</td>\n",
       "      <td>-1</td>\n",
       "      <td>96</td>\n",
       "      <td>-61</td>\n",
       "      <td>-13</td>\n",
       "      <td>20</td>\n",
       "      <td>-15</td>\n",
       "      <td>-13</td>\n",
       "      <td>104</td>\n",
       "      <td>-89</td>\n",
       "      <td>-153</td>\n",
       "      <td>-104</td>\n",
       "      <td>-143</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>debora</td>\n",
       "      <td>Woman</td>\n",
       "      <td>46</td>\n",
       "      <td>1.62</td>\n",
       "      <td>75</td>\n",
       "      <td>28.6</td>\n",
       "      <td>-2</td>\n",
       "      <td>95</td>\n",
       "      <td>-62</td>\n",
       "      <td>-14</td>\n",
       "      <td>19</td>\n",
       "      <td>-16</td>\n",
       "      <td>-13</td>\n",
       "      <td>104</td>\n",
       "      <td>-89</td>\n",
       "      <td>-153</td>\n",
       "      <td>-104</td>\n",
       "      <td>-142</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user gender  age  how_tall_in_meters  weight  body_mass_index  x1  y1  \\\n",
       "0  debora  Woman   46                1.62      75             28.6  -3  92   \n",
       "1  debora  Woman   46                1.62      75             28.6  -3  94   \n",
       "2  debora  Woman   46                1.62      75             28.6  -1  97   \n",
       "3  debora  Woman   46                1.62      75             28.6  -2  96   \n",
       "4  debora  Woman   46                1.62      75             28.6  -1  96   \n",
       "5  debora  Woman   46                1.62      75             28.6  -2  95   \n",
       "\n",
       "   z1  x2  y2  z2  x3   y3  z3   x4   y4   z4    class  \n",
       "0 -63 -23  18 -19   5  104 -92 -150 -103 -147  sitting  \n",
       "1 -64 -21  18 -18 -14  104 -90 -149 -104 -145  sitting  \n",
       "2 -61 -12  20 -15 -13  104 -90 -151 -104 -144  sitting  \n",
       "3 -57 -15  21 -16 -13  104 -89 -153 -103 -142  sitting  \n",
       "4 -61 -13  20 -15 -13  104 -89 -153 -104 -143  sitting  \n",
       "5 -62 -14  19 -16 -13  104 -89 -153 -104 -142  sitting  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('HAR_data.txt', header=0, sep=';', decimal=',')\n",
    "\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features we will use to predict the class are age, BMI which is based on height and weight, and the orientation of the 4 sensors. Extract the features to a matrix X and standardize it to Xs.\n",
    "\n",
    "The 5 classes will be converted to numbers 0 to 4 and extracted to target variable y.\n",
    "<br>\n",
    "0 = sitting, 1 = sitting down, 2 = standing, 3 = standing up, 4 = walking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples = 165633, Number of attributes: 14\n"
     ]
    }
   ],
   "source": [
    "xnames = ['age','body_mass_index','x1','y1','z1','x2','y2','z2','x3','y3','z3','x4','y4','z4']\n",
    "X = np.array(df[xnames])\n",
    "Xs = preprocessing.scale(X)\n",
    "\n",
    "y = np.unique(df['class'],return_inverse=True)[1]\n",
    "\n",
    "nsamp = X.shape[0]\n",
    "natt = X.shape[1]\n",
    "print(\"Number of samples = %d, Number of attributes: %d\" %(nsamp,natt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression \n",
    "First we will use logistic regression and measure the accuracy on the training data without cross validation. \n",
    "<br>\n",
    "Create a `LogisticRegression` object and fit the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = linear_model.LogisticRegression(C=1e5)\n",
    "logreg.fit(Xs,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure the accuracy of the classifier. We will see that the accuracy is bad, so we will use cross validation on training and test data later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.827697\n"
     ]
    }
   ],
   "source": [
    "yhat = logreg.predict(Xs)\n",
    "acc = np.mean(yhat==y)\n",
    "print(\"Accuracy = %f\" %acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting the Weight Vector \n",
    "First we will look at the weight of each attribute and plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 3 artists>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEC5JREFUeJzt3X9s3PV9x/HXCyewI91qsmSMmIRAxTyh0iarxcoyTV2h\nc8qqJuWv0g1RrVL4Y6XdNBkl2h9DkzasmY5tWsWaUgbSaMrEgov6y6VkE9rEoKFGSSj1QAFCLoE4\nRW4ptUjivPfHnVPb2Mmd7/u9r7+fez4ky3cfXz73in1+3flzn++dI0IAgHScV3QAAEC2KHYASAzF\nDgCJodgBIDEUOwAkhmIHgMRQ7ACQGIodABJDsQNAYpYVcaWrVq2K9evXF3HVAFBazzzzzPGIWH2u\nyxVS7OvXr9fevXuLuGoAKC3brzRyOZZiACAxFDsAJIZiB4DEUOwAkBiKHQAS03Cx277P9jHbB2aM\n3WG7avvZ+scN+cQElpbh0ao2De7R5du/qU2DezQ8Wi06EnBGM4/Y75e0eZ7xuyNiQ/3jW9nEApau\n4dGqduzer+rEpEJSdWJSO3bvp9yxZDRc7BHxhKQ3cswClMLQyJgmT07NGps8OaWhkbGCEgGzZbHG\nfpvtffWlmosymA9Y0o5MTDY1DrRbq8V+j6QrJG2QdFTSFxa6oO1ttvfa3js+Pt7i1QLFWdNdaWoc\naLeWij0iXo+IqYg4LenLkq45y2V3RkRfRPStXn3OlzoAlqyB/l5VlnfNGqss79JAf29BiYDZWip2\n25fMOPsJSQcWuiyQiq0be3TnjVfr/K7ar09Pd0V33ni1tm7sKTgZUNPwi4DZ3iXpQ5JW2T4s6a8k\nfcj2Bkkh6WVJt+aQEVhytm7s0a6nD0mSHrr12oLTALM1XOwRcdM8w1/JMAsAIAMceQoAiaHYASAx\nFDsAJIZiB4DEUOwAkBiKHQASQ7EDQGIodgBIDMUOAImh2AEgMRQ7ACSGYgeAxFDsAJAYih0AEkOx\nA0BiKHYASAzFDgCJodgBIDEUOwAkhmIHgMRQ7ACQGIodABJDsQNAYih2AEgMxQ4AiaHYASAxFDsA\nJIZiB4DEUOwAkBiKHQASQ7EDQGIodgBIDMUOAImh2AEgMQ0Xu+37bB+zfWDG2Erbj9l+of75onxi\nAgAa1cwj9vslbZ4ztl3S4xFxpaTH6+cBAAVquNgj4glJb8wZ3iLpgfrpByRtzSgXAGCRWl1jvzgi\njtZPvybp4hbnAwC0KLMnTyMiJMVCX7e9zfZe23vHx8ezuloAwBytFvvrti+RpPrnYwtdMCJ2RkRf\nRPStXr26xasFACyk1WJ/VNIt9dO3SPp6i/MBAFrUzHbHXZKelNRr+7Dtz0galPQR2y9Iur5+HgBQ\noGWNXjAiblrgS9dllAUAkAGOPAWAxFDsAJAYih0AEkOxA0BiKHYASAzFDgCJodgBIDEUOwAkhmIH\ngMRQ7ACQGIodABJDsQNAYih2AEgMxQ4AiaHYASAxFDsAJIZiB4DEUOwAkBiKHQASQ7EDQGIodgBI\nDMUOAImh2AEgMRQ7ACSGYgeAxFDsAJAYih0AEkOxA0BiKHYASAzFDgCJodgBIDEUOwAkhmIHgMRQ\n7ACQmGVZTGL7ZUlvSpqSdCoi+rKYFwDQvEyKve73I+J4hvMBABaBpRgASExWxR6Svmf7GdvbMpoT\nALAIWS3F/G5EVG3/mqTHbP8oIp6YeYF64W+TpHXr1mV0tQCAuTJ5xB4R1frnY5IekXTNPJfZGRF9\nEdG3evXqLK4WADCPlh+x214h6byIeLN++g8k/XXLybAkDI9WNTQypiMTk1rTXdFAf6+2buwpOhaA\ns8hiKeZiSY/Ynp7vqxHxnQzmRcGGR6vasXu/Jk9OSZKqE5PasXu/JFHuwBLWcrFHxEFJ788gC5aY\noZGxM6U+bfLklIZGxih2YAljuyMWdGRisqlxAEsDxY4FremuNDUOYGmg2LGggf5eVZZ3zRqrLO/S\nQH9vQYkANCLLlxRAYqbX0W9/eJ9OTJ1WD7tigFKg2HFWWzf2aNfThyRJD916bcFpADSCpRgASAzF\nDgCJodgBIDEUOwAkhmIHgMRQ7ACQGIodABJDsQNAYih2AEgMxQ4AiaHYASAxFDsAJIZiB4DEUOwA\nkJjSvGzv8GhVQyNjOjIxqTW8LjgALKgUxT48WtWO3fvPvLFydWJSO3bvlyTKHQDmKMVSzNDI2JlS\nnzZ5ckpDI2MFJQKApasUxX5kYrKpcQDoZKUo9jXdlabGAaCTlaLYB/p7VVneNWussrxLA/29BSUC\ngKWrFE+eTj9BevvD+3Ri6rR62BUDLBo7zNJXimKXauW+6+lDkqSHbr224DRAObHDrDOUYikGQDbY\nYdYZKHagg7DDrDNQ7EAHYYdZZ6DYgQ7CDrPOUJonTwG0jh1mnYFiBzpMmXeYsVWzMRQ7sMRQXvNj\nq2bjMlljt73Z9pjtF21vz2JOoBNNl1d1YlKhX5TX8Gi16GiFK/tWzeHRqjYN7tHl27+pTYN7cv2Z\ntlzstrskfVHSRyVdJekm21e1Oi/QicpeXnkq81bNdt9hZ/GI/RpJL0bEwYg4IelrkrZkMC/Qccpc\nXnkr81bNdt9hZ7HG3iPp1RnnD0v67QzmfYfN//VV/fr4q3rlv38l87mP/+xtvXT8LU2dDl2wrEtr\nV1a06l0XZDb/yz9+S5K0/ldXZDZnO+aWpE8f/akk5fJ9zzt7nvPn8X25+9CE3j419Y7xC5Z16ZWb\nH8rsesr4M/2nn72tg8ff0unTcWbsvPOsK1at0Cs335/JdeSV/XMHf3zm9MF39+hL76s99s3rDrtt\nT57a3iZpmyStW7duUXOsXHGBLvxJ17kv2KTjc24wb5+a0sHjtR9wVuX+8xPv/GXNSp5zS9KF52f/\nPZ+Wd/Y858/j+7J2ZWXe8lq7MttHpWX8mU7/Lub5ACyv7Bcs65r3DjuvvzayKPaqpLUzzl9aH5sl\nInZK2ilJfX19Mffrjdhy712L+Wfn9KnBParOc8/Z013R/2z/cMvzD49Wc903fPuXnpSU39a1y3KZ\ntSbv7HnOn8f35TJJr86zK+YDGe/6KOvP9DJJH8h81l/IK/voaFV3zNjRI+V7YFgWxf59SVfavly1\nQv+kpE9lMG/b5LmuOf2kyYmp05LYooVz27qxh9tGYqZ/nu3axtpysUfEKduflTQiqUvSfRHxXMvJ\n2mhNd2XeR+xZ/Jl0tidN+OUFOkc777Az2cceEd+KiN+IiPdExN9kMWc75fn6GexyANBuvAiYavek\nd954tXq6K7Jqa+t33nh1JveuZd6iBaCceEmBurz+TBro7511GLTEq+khXcOjVY0emtCJqdPaNLin\nVC+HUObsc1HsOWv3kyZAUcq8UaDM2edDsbcBuxzQCcq8UaDM2efDGjuATJR5o0CZs8+HYgeQiTJv\nFChz9vlQ7AAyUea33Stz9vmwxg4gE2XeKFDm7POh2AFkpswbBcqcfS6WYgAgMRQ7ACSGYgeAxFDs\nAJAYih0AEkOxA0BiKHYASAzFDgCJodgBIDEUOwAkhmIHgMRQ7ACQGIodABJDsQNAYij2kpt+Z/Wn\nXnpDmwb3aHi0WnQkAAWj2EtsoXdWp9yBzkaxl9jZ3lkdQOei2EsstXdWB5ANir3EUntndQDZoNhL\nLLV3VgeQDd7MusRSe2d1ANmg2EsupXdWB5ANlmIAIDEUOwAkhmIHgMS0VOy277Bdtf1s/eOGrIIB\nABYniydP746IuzKYBwCQAZZiACAxWRT7bbb32b7P9kUZzAcAaME5i93292wfmOdji6R7JF0haYOk\no5K+cJZ5ttnea3vv+Ph4Zv8BAMBs51xjj4jrG5nI9pclfeMs8+yUtFOS+vr6otGAAIDmtLor5pIZ\nZz8h6UBrcQAArWp1V8zf2d4gKSS9LOnWlhMBAFrSUrFHxM1ZBQEAZIPtjgCQGIodABJDsQNAYih2\nAEgMxQ4AiaHYASAxFDsAJIZiR7KGR6saPTShp156Q5sG92h4tFp0JKAtKHYkaXi0qh279+vE1GlJ\nUnViUjt276fc0REodiRpaGRMkyenZo1NnpzS0MhYQYmA9qHYkaQjE5NNjQMpodiRpDXdlabGgZRQ\n7EjSQH+vKsu7Zo1VlndpoL+3oERA+2TxZtbAkrN1Y4+k2lr7kYlJremuaKC/98w4kDKKHcnaurGH\nIkdHYikGABJDsQNAYih2FIYjQ4F8UOwoBEeGAvmh2FEIjgwF8kOxoxAcGQrkh2JHITgyFMgPxY5C\ncGQokB8OUEIhODIUyA/FjsJwZCiQD5ZiACAxFDsAJIZiB4DEUOwAkBiKHQAS44ho/5Xa45JeWeQ/\nXyXpeIZx2onsxShr9rLmlsiel8siYvW5LlRIsbfC9t6I6Cs6x2KQvRhlzV7W3BLZi8ZSDAAkhmIH\ngMSUsdh3Fh2gBWQvRlmzlzW3RPZClW6NHQBwdmV8xA4AOItSFbvtzbbHbL9oe3vReRple63t/7T9\nQ9vP2f580ZmaYbvL9qjtbxSdpRm2u20/bPtHtp+3fW3RmRpl+8/rt5UDtnfZ/qWiMy3E9n22j9k+\nMGNspe3HbL9Q/3xRkRkXskD2ofptZp/tR2x3F5lxMUpT7La7JH1R0kclXSXpJttXFZuqYack/UVE\nXCXpg5L+tETZJenzkp4vOsQi/KOk70TEb0p6v0ryf7DdI+lzkvoi4r2SuiR9sthUZ3W/pM1zxrZL\nejwirpT0eP38UnS/3pn9MUnvjYj3Sfo/STvaHapVpSl2SddIejEiDkbECUlfk7Sl4EwNiYijEfGD\n+uk3VSuYUrxere1LJf2hpHuLztIM2++W9HuSviJJEXEiIiaKTdWUZZIqtpdJulDSkYLzLCginpD0\nxpzhLZIeqJ9+QNLWtoZq0HzZI+K7EXGqfvZ/JV3a9mAtKlOx90h6dcb5wypJOc5ke72kjZKeKjZJ\nw/5B0u2SThcdpEmXSxqX9K/1ZaR7ba8oOlQjIqIq6S5JhyQdlfSTiPhusamadnFEHK2ffk3SxUWG\nacGfSPp20SGaVaZiLz3b75L0H5L+LCJ+WnSec7H9MUnHIuKZorMswjJJvyXpnojYKOktLd3lgFnq\n69FbVLtzWiNphe0/LjbV4kVt613ptt/Z/kvVllEfLDpLs8pU7FVJa2ecv7Q+Vgq2l6tW6g9GxO6i\n8zRok6SP235ZtaWvD9v+t2IjNeywpMMRMf2X0cOqFX0ZXC/ppYgYj4iTknZL+p2CMzXrdduXSFL9\n87GC8zTF9qclfUzSH0UJ94SXqdi/L+lK25fbPl+1J5MeLThTQ2xbtbXe5yPi74vO06iI2BERl0bE\netW+33siohSPHCPiNUmv2p5+d+zrJP2wwEjNOCTpg7YvrN92rlNJnvid4VFJt9RP3yLp6wVmaYrt\nzaotP348In5edJ7FKE2x15/M+KykEdVu5P8eEc8Vm6phmyTdrNoj3mfrHzcUHaoD3CbpQdv7JG2Q\n9LcF52lI/a+MhyX9QNJ+1X5Pl+zRkLZ3SXpSUq/tw7Y/I2lQ0kdsv6DaXyCDRWZcyALZ/1nSL0t6\nrP67+i+FhlwEjjwFgMSU5hE7AKAxFDsAJIZiB4DEUOwAkBiKHQASQ7EDQGIodgBIDMUOAIn5f894\nhqMYImbgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e2d4dbdf28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = logreg.coef_[0]\n",
    "plt.stem(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will find the three attributes with the highest magnitude weight. \n",
    "<br> \n",
    "It turns out that y2, x2,and z2 has the largest weight, so the orientation of sensor 2 (accelerometer put on the left thigh) has a huge affect on the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The three attributes with the largest |weight| is: y2, x2, and z2\n"
     ]
    }
   ],
   "source": [
    "wmag = np.absolute(w)\n",
    "ind = np.argsort(wmag)[-3:]\n",
    "\n",
    "print(\"The three attributes with the largest |weight| is: %s, %s, and %s\" %(xnames[ind[0]],xnames[ind[1]],xnames[ind[2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "Next we will perform a 10-fold cross validation on training and test sets. Shuffle the data since the classes are bunched together. \n",
    "<br>\n",
    "Create a confusion matrix C by measuring and adding the confusion matrix across all folds. Normalize the rows of the matrix. \n",
    "<br>\n",
    "Print the overall mean and SE of the test error rate across the folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.99999  0.       0.       0.00001  0.     ]\n",
      " [ 0.01546  0.74248  0.17773  0.05009  0.01424]\n",
      " [ 0.       0.00004  0.98434  0.       0.01562]\n",
      " [ 0.00968  0.05599  0.13769  0.76661  0.03003]\n",
      " [ 0.       0.00008  0.07547  0.00053  0.92392]]\n",
      "\n",
      "Error rate mean = 0.1724, SE = 0.0009\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAScAAAD8CAYAAAA11GIZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nU0QU6X8BKqMRBelEhmUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e2d60cfb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "nfold = 10 \n",
    "kf = KFold(n_splits=nfold, shuffle=True) \n",
    "\n",
    "C = np.zeros((5,5))\n",
    "err_rate = np.zeros(nfold)\n",
    "\n",
    "for ifold, Ind in enumerate(kf.split(Xs)):\n",
    "    \n",
    "    Itr,Its, = Ind\n",
    "    Xtr = Xs[Itr,:]\n",
    "    ytr = y[Itr]\n",
    "    Xts = Xs[Its,:]\n",
    "    yts = y[Its]\n",
    "    \n",
    "    logreg.fit(Xtr,ytr)\n",
    "    yhat = logreg.predict(Xts)\n",
    "    \n",
    "    C = C + confusion_matrix(yts,yhat)\n",
    "    err_rate[ifold] = np.mean(yhat != yts)\n",
    "\n",
    "Cnorm = preprocessing.normalize(C,axis=1)\n",
    "Cnorm = np.square(Cnorm) \n",
    "\n",
    "print(np.array_str(Cnorm, precision=5, suppress_small=True))\n",
    "plt.imshow(Cnorm, interpolation='none')\n",
    "plt.colorbar()\n",
    "\n",
    "err_mean = np.mean(err_rate)\n",
    "err_se = np.std(err_rate)/np.sqrt(nfold-1)\n",
    "\n",
    "print('')\n",
    "print(\"Error rate mean = {0:.4f}, SE = {1:.4f}\".format(err_mean, err_se))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy seems pretty good for classes 0,2, and 4 (92%+) but not for classes 1 and 3 (~75%). \n",
    "<br>\n",
    "The error is probably because there are a lot less samples for classes 1 and 3. (sitting down and standing up)\n",
    "<br>\n",
    "Next we will use Support Vector Machines to get a better accuracy.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM):\n",
    "Create a SVM classifer. Use an \"rbf\" classifier with C=2.8 and gamma=0.0073."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svc = svm.SVC(probability=False, kernel='rbf', C=2.8, gamma=.0073,verbose=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use about half of the samples for training and half for testing. Randomly select them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ntr = 80000\n",
    "nts = 80000\n",
    "ns = ntr + nts \n",
    "\n",
    "Iperm = np.random.permutation(nsamp)\n",
    "\n",
    "Xtr = Xs[Iperm[:ntr],:]\n",
    "ytr = y[Iperm[:ntr]]\n",
    "Xts = Xs[Iperm[ntr:ns],:]\n",
    "yts = y[Iperm[ntr:ns]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the training data. The fitting and predicting commands will take a few minutes since there are 160,000 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=2.8, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.0073, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(Xtr,ytr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure the accuracy on the test samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.947738\n"
     ]
    }
   ],
   "source": [
    "yhat = svc.predict(Xts)\n",
    "accuracy = np.mean(yhat==yts)\n",
    "print(\"Accuracy = %f\" %accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the normalized confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Teddy\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype int32 was converted to float64 by the normalize function.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.99999  0.       0.       0.00001  0.     ]\n",
      " [ 0.00059  0.99439  0.00361  0.00137  0.00005]\n",
      " [ 0.       0.       0.99984  0.       0.00016]\n",
      " [ 0.0004   0.00664  0.02573  0.9669   0.00033]\n",
      " [ 0.       0.00006  0.00607  0.00004  0.99383]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x1e2d618de48>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAScAAAD8CAYAAAA11GIZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRUSREk4RUaT/AzsKA+J9xGbGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e2d605cc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "C2 = confusion_matrix(yts,yhat)\n",
    "\n",
    "Cnorm2 = preprocessing.normalize(C2,axis=1)\n",
    "Cnorm2 = np.square(Cnorm2) \n",
    "\n",
    "print(np.array_str(Cnorm2, precision=5, suppress_small=True))\n",
    "plt.imshow(Cnorm2, interpolation='none')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the accuracy of the classifier is about 95%, which is much better than before. \n",
    "<br> \n",
    "To get an even better accuracy, we can try neural networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Classifier:\n",
    "Load the keras packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear previous model layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like before, use 80,000 samples as training and test set. Scale the feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtr = X[Iperm[:ntr],:]\n",
    "ytr = y[Iperm[:ntr]]\n",
    "Xts = X[Iperm[ntr:ns],:]\n",
    "yts = y[Iperm[ntr:ns]]\n",
    "\n",
    "X_mean = np.mean(Xtr,axis=0)\n",
    "X_std = np.std(Xtr,axis=0)\n",
    "\n",
    "Xtr_scale = (Xtr - X_mean)/ X_std\n",
    "Xts_scale = (Xts - X_mean)/ X_std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a neural network model with: \n",
    "* nh = 256 hidden units \n",
    "* sigmoid activation\n",
    "* output activation as softmax for multi-class targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nin = Xtr.shape[1]\n",
    "nout = np.max(ytr)+1  # 5 classes\n",
    "nh = 256\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(nh, input_shape=(nin,), activation='sigmoid', name='hidden'))\n",
    "model.add(Dense(nout, activation = 'softmax', name='output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden (Dense)               (None, 256)               3840      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 5,125\n",
      "Trainable params: 5,125\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an optimizer and compile the model. Use the Adam optimizer with a learning rate of 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import optimizers \n",
    "\n",
    "opt = optimizers.Adam(lr=0.001)\n",
    "model.compile(optimizer=opt,\n",
    "             loss ='sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model for 10 epochs using the scaled data for both training and validation. Use a batch size of 100.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 80000 samples\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 9s 111us/step - loss: 0.6503 - acc: 0.7807 - val_loss: 0.4979 - val_acc: 0.8294\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 8s 96us/step - loss: 0.4561 - acc: 0.8399 - val_loss: 0.4279 - val_acc: 0.8431\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 8s 94us/step - loss: 0.3612 - acc: 0.8781 - val_loss: 0.3197 - val_acc: 0.8957\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - 8s 95us/step - loss: 0.2811 - acc: 0.9118 - val_loss: 0.2533 - val_acc: 0.9206\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 8s 97us/step - loss: 0.2323 - acc: 0.9277 - val_loss: 0.2147 - val_acc: 0.9346\n",
      "Epoch 6/10\n",
      "80000/80000 [==============================] - 8s 95us/step - loss: 0.1985 - acc: 0.9389 - val_loss: 0.1869 - val_acc: 0.9444\n",
      "Epoch 7/10\n",
      "80000/80000 [==============================] - 8s 95us/step - loss: 0.1722 - acc: 0.9468 - val_loss: 0.1625 - val_acc: 0.9493\n",
      "Epoch 8/10\n",
      "80000/80000 [==============================] - 8s 95us/step - loss: 0.1509 - acc: 0.9536 - val_loss: 0.1427 - val_acc: 0.9565\n",
      "Epoch 9/10\n",
      "80000/80000 [==============================] - 8s 95us/step - loss: 0.1335 - acc: 0.9602 - val_loss: 0.1294 - val_acc: 0.9633\n",
      "Epoch 10/10\n",
      "80000/80000 [==============================] - 8s 95us/step - loss: 0.1191 - acc: 0.9647 - val_loss: 0.1142 - val_acc: 0.9664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e2ded7dc18>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "model.fit(Xtr_scale, ytr, epochs=10, batch_size=batch_size, validation_data=(Xts_scale,yts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy should be around 96% after 10 epochs. We can fit the model again for another 10 epochs for a greater accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 80000 samples\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 8s 94us/step - loss: 0.1072 - acc: 0.9685 - val_loss: 0.1051 - val_acc: 0.9692\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 8s 94us/step - loss: 0.0974 - acc: 0.9719 - val_loss: 0.0946 - val_acc: 0.9734\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 8s 99us/step - loss: 0.0892 - acc: 0.9742 - val_loss: 0.0895 - val_acc: 0.9740\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - 8s 95us/step - loss: 0.0826 - acc: 0.9765 - val_loss: 0.0837 - val_acc: 0.9756\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 8s 94us/step - loss: 0.0767 - acc: 0.9778 - val_loss: 0.0773 - val_acc: 0.9775\n",
      "Epoch 6/10\n",
      "80000/80000 [==============================] - 8s 95us/step - loss: 0.0721 - acc: 0.9792 - val_loss: 0.0724 - val_acc: 0.9790\n",
      "Epoch 7/10\n",
      "80000/80000 [==============================] - 8s 94us/step - loss: 0.0676 - acc: 0.9807 - val_loss: 0.0680 - val_acc: 0.9804\n",
      "Epoch 8/10\n",
      "80000/80000 [==============================] - 8s 100us/step - loss: 0.0639 - acc: 0.9815 - val_loss: 0.0672 - val_acc: 0.9793\n",
      "Epoch 9/10\n",
      "80000/80000 [==============================] - 8s 95us/step - loss: 0.0606 - acc: 0.9828 - val_loss: 0.0614 - val_acc: 0.9817\n",
      "Epoch 10/10\n",
      "80000/80000 [==============================] - 8s 96us/step - loss: 0.0575 - acc: 0.9834 - val_loss: 0.0596 - val_acc: 0.9819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e2ec3acf98>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtr_scale, ytr, epochs=10, batch_size=batch_size, validation_data=(Xts_scale,yts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After another 10 epochs, the accuracy increased to 98%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "It seems like for HAR projects like this, neural networks work better than SVMs. In the chart of previous HAR researches, the highest NN accuracy was 99.6% and highest for SVM alone was 98.1%. When SVM was used together with other algorithms like Naive Bayes, the accuracy was as high as 99.4%. \n",
    "<br> \n",
    "\n",
    "Since the accuracy is this high for several classifiers, future works can include more classes so that we can predict more types of movements. The goal of the future is to monitor every single movements with the least amount of sensors and displaying it on a screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
